{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Implimenting Attention Model</h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference : https://github.com/thushv89/attention_keras/blob/master/src/layers/attention.py\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    \"\"\"\n",
    "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
    "    There are three sets of weights introduced W_a, U_a, and V_a\n",
    "     \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "\n",
    "        self.W_a = self.add_weight(name='W_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a',\n",
    "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs, verbose=False):\n",
    "        \"\"\"\n",
    "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        assert type(inputs) == list\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "        if verbose:\n",
    "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
    "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
    "\n",
    "        def energy_step(inputs, states):\n",
    "            \"\"\" Step function for computing energy for a single decoder state\n",
    "            inputs: (batchsize * 1 * de_in_dim)\n",
    "            states: (batchsize * 1 * de_latent_dim)\n",
    "            \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
    "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
    "            de_hidden = inputs.shape[-1]\n",
    "\n",
    "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
    "            # <= batch size * en_seq_len * latent_dim\n",
    "            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n",
    "\n",
    "            \"\"\" Computing hj.Ua \"\"\"\n",
    "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
    "            if verbose:\n",
    "                print('Ua.h>', U_a_dot_h.shape)\n",
    "\n",
    "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
    "            if verbose:\n",
    "                print('Ws+Uh>', Ws_plus_Uh.shape)\n",
    "\n",
    "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.softmax(e_i)\n",
    "\n",
    "            if verbose:\n",
    "                print('ei>', e_i.shape)\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        def context_step(inputs, states):\n",
    "            \"\"\" Step function for computing ci using ei \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "            if verbose:\n",
    "                print('ci>', c_i.shape)\n",
    "            return c_i, [c_i]\n",
    "\n",
    "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
    "        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n",
    "\n",
    "        \"\"\" Computing energy outputs \"\"\"\n",
    "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
    "        last_out, e_outputs, _ = K.rnn(\n",
    "            energy_step, decoder_out_seq, [fake_state_e],\n",
    "        )\n",
    "\n",
    "        \"\"\" Computing context vectors \"\"\"\n",
    "        last_out, c_outputs, _ = K.rnn(\n",
    "            context_step, e_outputs, [fake_state_c],\n",
    "        )\n",
    "\n",
    "        return c_outputs, e_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\" Outputs produced by the layer \"\"\"\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data PreProcessing\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For our Model we are Using Amazon Fine reviews dataset\n",
    "\n",
    "data=pd.read_csv(\"Reviews.csv\",nrows=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove null values and dupicate values\n",
    "\n",
    "data.drop_duplicates(subset=['Text'],inplace=True)#dropping duplicates\n",
    "data.dropna(axis=0,inplace=True)#dropping na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 88421 entries, 0 to 99999\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   Id                      88421 non-null  int64 \n",
      " 1   ProductId               88421 non-null  object\n",
      " 2   UserId                  88421 non-null  object\n",
      " 3   ProfileName             88421 non-null  object\n",
      " 4   HelpfulnessNumerator    88421 non-null  int64 \n",
      " 5   HelpfulnessDenominator  88421 non-null  int64 \n",
      " 6   Score                   88421 non-null  int64 \n",
      " 7   Time                    88421 non-null  int64 \n",
      " 8   Summary                 88421 non-null  object\n",
      " 9   Text                    88421 non-null  object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 7.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "As machine is unable to compute such contractions hence\n",
    "we need to remove it\n",
    "'''\n",
    "contraction_mapping = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who's\": \"who is\",\n",
    "\"won't\": \"will not\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you're\": \"you are\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "#Text Preprocessing\n",
    "def text_cleaner(text,num):\n",
    "    newString = text.lower()\n",
    "    newString = BeautifulSoup(newString, \"lxml\").text\n",
    "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
    "    newString = re.sub('\"','', newString)\n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
    "    newString = re.sub('[m]{2,}', 'mm', newString)\n",
    "    if(num==0):\n",
    "        tokens = [w for w in newString.split() if not w in stop_words]\n",
    "    else:\n",
    "        tokens=newString.split()\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>1:                                                 #removing short word\n",
    "            long_words.append(i)   \n",
    "    return (\" \".join(long_words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the function for Reviews\n",
    "cleaned_text = []\n",
    "for t in data['Text']:\n",
    "    cleaned_text.append(text_cleaner(t,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better',\n",
       " 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo',\n",
       " 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch',\n",
       " 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal',\n",
       " 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the function fpr summaries \n",
    "cleaned_summary = []\n",
    "for t in data['Summary']:\n",
    "    cleaned_summary.append(text_cleaner(t,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good quality dog food',\n",
       " 'not as advertised',\n",
       " 'delight says it all',\n",
       " 'cough medicine',\n",
       " 'great taffy',\n",
       " 'nice taffy',\n",
       " 'great just as good as the expensive brands',\n",
       " 'wonderful tasty taffy',\n",
       " 'yay barley',\n",
       " 'healthy dog food']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_summary[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cleaned_text']=cleaned_text\n",
    "data['cleaned_summary']=cleaned_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace('', np.nan, inplace=True)\n",
    "data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_word_count = []\n",
    "summary_word_count = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in data['cleaned_text']:\n",
    "      text_word_count.append(len(i.split()))\n",
    "\n",
    "for i in data['cleaned_summary']:\n",
    "      summary_word_count.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
    "\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9425133841156297\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "for i in data['cleaned_summary']:\n",
    "    if(len(i.split())<=8):\n",
    "        cnt=cnt+1\n",
    "print(cnt/len(data['cleaned_summary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_len=30\n",
    "max_summary_len=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text =np.array(data['cleaned_text'])\n",
    "cleaned_summary=np.array(data['cleaned_summary'])\n",
    "\n",
    "short_text=[]\n",
    "short_summary=[]\n",
    "\n",
    "for i in range(len(cleaned_text)):\n",
    "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
    "        short_text.append(cleaned_text[i])\n",
    "        short_summary.append(cleaned_summary[i])\n",
    "        \n",
    "df=pd.DataFrame({'text':short_text,'summary':short_summary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Embeddings we need Start tag and end tag for each sentence sepratly\n",
    "\n",
    "df['summary'] = df['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization and Creaton of Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['summary']),test_size=0.1,random_state=0,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(list(x_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 66.12054772517368\n",
      "Total Coverage of rare words: 2.9537961717161627\n"
     ]
    }
   ],
   "source": [
    "thresh=4\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in x_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "#padding zero upto maximum length\n",
    "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
    "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
    "\n",
    "#size of vocabulary ( +1 for padding token)\n",
    "x_voc   =  x_tokenizer.num_words + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8438"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer()   \n",
    "y_tokenizer.fit_on_texts(list(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 78.21782178217822\n",
      "Total Coverage of rare words: 5.405320306947706\n"
     ]
    }
   ],
   "source": [
    "thresh=6\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in y_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
    "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
    "\n",
    "#padding zero upto maximum length\n",
    "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
    "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
    "\n",
    "#size of vocabulary\n",
    "y_voc  =   y_tokenizer.num_words +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42453, 42453)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tokenizer.word_counts['sostok'],len(y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=[]\n",
    "for i in range(len(y_tr)):\n",
    "    cnt=0\n",
    "    for j in y_tr[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_tr=np.delete(y_tr,ind, axis=0)\n",
    "x_tr=np.delete(x_tr,ind, axis=0)\n",
    "\n",
    "\n",
    "ind=[]\n",
    "for i in range(len(y_val)):\n",
    "    cnt=0\n",
    "    for j in y_val[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_val=np.delete(y_val,ind, axis=0)\n",
    "x_val=np.delete(x_val,ind, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU and LSTM both are better then Simple RNN.Overall LSTM is better then gru thus we selected LSTM for use.<br>\n",
    "\n",
    "Bidirectional LSTM is slower but gives better result hence for Encoder Bidirectional LSTM is used.\n",
    "<br>\n",
    "\n",
    "for Encoder : Bidirecional Lstm is used<br>\n",
    "For Decoder : Unidirectional LSTM is used<br>\n",
    "<br>\n",
    "Bahadanu Attention Model is used for picking up most likely sentence\n",
    "<br>\n",
    "Beam search is used as inference<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper Parameters\n",
    "\n",
    "latent_dim = 300\n",
    "embedding_dim=100\n",
    "epochs = 50\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K \n",
    "K.clear_session()\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "from keras.layers import Dense,LSTM,Input,Activation,Add,TimeDistributed,Flatten,RepeatVector,Lambda,Multiply,Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#encoder lstm layer 1\\nencoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\\nencoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\\n\\n#encoder lstm layer 2\\nencoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\\nencoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\\n\\n#encoder lstm layer 3\\nencoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\\nencoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoder side\n",
    "\n",
    "encoder_inputs = Input(shape=(max_text_len,))\n",
    "\n",
    "#embedding layer\n",
    "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
    "\n",
    "#Bidirectional LSTM layer 1\n",
    "encoder_LSTM1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_LSTM_rev1=LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.05,recurrent_dropout=0.4,go_backwards=True)\n",
    "    \n",
    "encoder_outputs1, state_h1, state_c1 = encoder_LSTM1(enc_emb)\n",
    "encoder_outputsR1, state_hR1, state_cR1 = encoder_LSTM_rev1(enc_emb)\n",
    "    \n",
    "state_hfinal1=Add()([state_h1,state_hR1])\n",
    "state_cfinal1=Add()([state_c1,state_cR1])\n",
    "\n",
    "\n",
    "#Layer 2\n",
    "encoder_LSTM = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_LSTM_rev=LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.05,recurrent_dropout=0.4,go_backwards=True)\n",
    "    \n",
    "encoder_outputs, state_h, state_c = encoder_LSTM(encoder_outputs1)\n",
    "encoder_outputsR, state_hR, state_cR = encoder_LSTM_rev(encoder_outputsR1)\n",
    "    \n",
    "state_hfinal=Add()([state_h,state_hR])\n",
    "state_cfinal=Add()([state_c,state_cR])\n",
    "encoder_outputs_final = Add()([encoder_outputs,encoder_outputsR])\n",
    "\n",
    "encoder_states = [state_hfinal,state_cfinal]\n",
    "\n",
    "'''\n",
    "#encoder lstm layer 1\n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "#encoder lstm layer 2\n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "#encoder lstm layer 3\n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "#decoder side embedding layer\n",
    "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "#Unidirectional LSTM for Decoder\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bahadanu attention model for better accuracy\n",
    "\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "attn_out, attn_states = attn_layer([encoder_outputs_final, decoder_outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Concat attention input and decoder LSTM output before Producing \n",
    "    actual output'''\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 30, 100)      843800      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 30, 300), (N 481200      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 30, 300), (N 481200      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 30, 300), (N 721200      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, 30, 300), (N 721200      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 100)    198100      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 300)          0           lstm_2[0][1]                     \n",
      "                                                                 lstm_3[0][1]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 300)          0           lstm_2[0][2]                     \n",
      "                                                                 lstm_3[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, None, 300),  481200      embedding_1[0][0]                \n",
      "                                                                 add_2[0][0]                      \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 30, 300)      0           lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 300),  180300      add_4[0][0]                      \n",
      "                                                                 lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 600)    0           lstm_4[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 1981)   1190581     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 5,298,781\n",
      "Trainable params: 5,298,781\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "# Define the model \n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 1323s 4s/step - loss: 2.8128 - val_loss: 2.5665\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=1,callbacks=[es],batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Always save your weights to avoid training everytime\n",
    "model.save_weights('summarization_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the weights\n",
    "model.load_weights('summarization_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Dictionary for target to source vocabulary\n",
    "summ_index_word = y_tokenizer.index_word\n",
    "text_index_word = x_tokenizer.index_word\n",
    "summ_word_index = y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sostok': 1,\n",
       " 'eostok': 2,\n",
       " 'great': 3,\n",
       " 'good': 4,\n",
       " 'the': 5,\n",
       " 'best': 6,\n",
       " 'not': 7,\n",
       " 'for': 8,\n",
       " 'love': 9,\n",
       " 'coffee': 10,\n",
       " 'and': 11,\n",
       " 'it': 12,\n",
       " 'my': 13,\n",
       " 'tea': 14,\n",
       " 'product': 15,\n",
       " 'this': 16,\n",
       " 'delicious': 17,\n",
       " 'is': 18,\n",
       " 'very': 19,\n",
       " 'taste': 20,\n",
       " 'but': 21,\n",
       " 'yummy': 22,\n",
       " 'excellent': 23,\n",
       " 'to': 24,\n",
       " 'of': 25,\n",
       " 'dog': 26,\n",
       " 'these': 27,\n",
       " 'flavor': 28,\n",
       " 'price': 29,\n",
       " 'tasty': 30,\n",
       " 'like': 31,\n",
       " 'favorite': 32,\n",
       " 'ever': 33,\n",
       " 'in': 34,\n",
       " 'too': 35,\n",
       " 'loves': 36,\n",
       " 'food': 37,\n",
       " 'stuff': 38,\n",
       " 'snack': 39,\n",
       " 'awesome': 40,\n",
       " 'so': 41,\n",
       " 'yum': 42,\n",
       " 'dogs': 43,\n",
       " 'are': 44,\n",
       " 'as': 45,\n",
       " 'just': 46,\n",
       " 'chocolate': 47,\n",
       " 'them': 48,\n",
       " 'with': 49,\n",
       " 'healthy': 50,\n",
       " 'wonderful': 51,\n",
       " 'nice': 52,\n",
       " 'free': 53,\n",
       " 'perfect': 54,\n",
       " 'better': 55,\n",
       " 'you': 56,\n",
       " 'on': 57,\n",
       " 'treats': 58,\n",
       " 'treat': 59,\n",
       " 'tastes': 60,\n",
       " 'no': 61,\n",
       " 'really': 62,\n",
       " 'tasting': 63,\n",
       " 'quality': 64,\n",
       " 'than': 65,\n",
       " 'what': 66,\n",
       " 'sweet': 67,\n",
       " 'cup': 68,\n",
       " 'hot': 69,\n",
       " 'have': 70,\n",
       " 'at': 71,\n",
       " 'chips': 72,\n",
       " 'buy': 73,\n",
       " 'bad': 74,\n",
       " 'amazing': 75,\n",
       " 'popcorn': 76,\n",
       " 'one': 77,\n",
       " 'little': 78,\n",
       " 'gluten': 79,\n",
       " 'cat': 80,\n",
       " 'all': 81,\n",
       " 'cookies': 82,\n",
       " 'sugar': 83,\n",
       " 'organic': 84,\n",
       " 'mix': 85,\n",
       " 'do': 86,\n",
       " 'value': 87,\n",
       " 'easy': 88,\n",
       " 'ok': 89,\n",
       " 'me': 90,\n",
       " 'candy': 91,\n",
       " 'green': 92,\n",
       " 'deal': 93,\n",
       " 'cereal': 94,\n",
       " 'your': 95,\n",
       " 'from': 96,\n",
       " 'pretty': 97,\n",
       " 'fantastic': 98,\n",
       " 'they': 99,\n",
       " 'happy': 100,\n",
       " 'way': 101,\n",
       " 'gift': 102,\n",
       " 'cats': 103,\n",
       " 'amazon': 104,\n",
       " 'bars': 105,\n",
       " 'salt': 106,\n",
       " 'sauce': 107,\n",
       " 'cups': 108,\n",
       " 'was': 109,\n",
       " 'bar': 110,\n",
       " 'much': 111,\n",
       " 'expensive': 112,\n",
       " 'works': 113,\n",
       " 'fresh': 114,\n",
       " 'drink': 115,\n",
       " 'rice': 116,\n",
       " 'only': 117,\n",
       " 'service': 118,\n",
       " 'strong': 119,\n",
       " 'more': 120,\n",
       " 'review': 121,\n",
       " 'that': 122,\n",
       " 'breakfast': 123,\n",
       " 'be': 124,\n",
       " 'baby': 125,\n",
       " 'loved': 126,\n",
       " 'bread': 127,\n",
       " 'oil': 128,\n",
       " 'will': 129,\n",
       " 'out': 130,\n",
       " 'blend': 131,\n",
       " 'decaf': 132,\n",
       " 'real': 133,\n",
       " 'our': 134,\n",
       " 'did': 135,\n",
       " 'does': 136,\n",
       " 'can': 137,\n",
       " 'syrup': 138,\n",
       " 'pasta': 139,\n",
       " 'low': 140,\n",
       " 'super': 141,\n",
       " 'wow': 142,\n",
       " 'cannot': 143,\n",
       " 'eat': 144,\n",
       " 'soup': 145,\n",
       " 'go': 146,\n",
       " 'high': 147,\n",
       " 'greenies': 148,\n",
       " 'quick': 149,\n",
       " 'water': 150,\n",
       " 'find': 151,\n",
       " 'fast': 152,\n",
       " 'hard': 153,\n",
       " 'get': 154,\n",
       " 'up': 155,\n",
       " 'made': 156,\n",
       " 'coconut': 157,\n",
       " 'chai': 158,\n",
       " 'expected': 159,\n",
       " 'time': 160,\n",
       " 'salty': 161,\n",
       " 'mm': 162,\n",
       " 'disappointed': 163,\n",
       " 'smooth': 164,\n",
       " 'old': 165,\n",
       " 'shipping': 166,\n",
       " 'dark': 167,\n",
       " 'an': 168,\n",
       " 'cocoa': 169,\n",
       " 'makes': 170,\n",
       " 'kids': 171,\n",
       " 'vanilla': 172,\n",
       " 'butter': 173,\n",
       " 'money': 174,\n",
       " 'item': 175,\n",
       " 'or': 176,\n",
       " 'had': 177,\n",
       " 'alternative': 178,\n",
       " 'if': 179,\n",
       " 'big': 180,\n",
       " 'there': 181,\n",
       " 'stale': 182,\n",
       " 'new': 183,\n",
       " 'jerky': 184,\n",
       " 'spicy': 185,\n",
       " 'again': 186,\n",
       " 'nuts': 187,\n",
       " 'refreshing': 188,\n",
       " 'we': 189,\n",
       " 'would': 190,\n",
       " 'honey': 191,\n",
       " 'well': 192,\n",
       " 'small': 193,\n",
       " 'chicken': 194,\n",
       " 'okay': 195,\n",
       " 'energy': 196,\n",
       " 'natural': 197,\n",
       " 'crackers': 198,\n",
       " 'worth': 199,\n",
       " 'use': 200,\n",
       " 'horrible': 201,\n",
       " 'white': 202,\n",
       " 'right': 203,\n",
       " 'yuck': 204,\n",
       " 'cookie': 205,\n",
       " 'cheese': 206,\n",
       " 'ginger': 207,\n",
       " 'gum': 208,\n",
       " 'convenient': 209,\n",
       " 'fruit': 210,\n",
       " 'packaging': 211,\n",
       " 'black': 212,\n",
       " 'pop': 213,\n",
       " 'awful': 214,\n",
       " 'bold': 215,\n",
       " 'noodles': 216,\n",
       " 'milk': 217,\n",
       " 'light': 218,\n",
       " 'by': 219,\n",
       " 'terrible': 220,\n",
       " 'weak': 221,\n",
       " 'without': 222,\n",
       " 'chews': 223,\n",
       " 'pricey': 224,\n",
       " 'nothing': 225,\n",
       " 'roast': 226,\n",
       " 'its': 227,\n",
       " 'yumm': 228,\n",
       " 'em': 229,\n",
       " 'peanut': 230,\n",
       " 'far': 231,\n",
       " 'pumpkin': 232,\n",
       " 'bag': 233,\n",
       " 'pack': 234,\n",
       " 'juice': 235,\n",
       " 'has': 236,\n",
       " 'absolutely': 237,\n",
       " 'seeds': 238,\n",
       " 'poor': 239,\n",
       " 'addictive': 240,\n",
       " 'wrong': 241,\n",
       " 'overpriced': 242,\n",
       " 'could': 243,\n",
       " 'enough': 244,\n",
       " 'licorice': 245,\n",
       " 'fabulous': 246,\n",
       " 'some': 247,\n",
       " 'cheaper': 248,\n",
       " 'beef': 249,\n",
       " 'am': 250,\n",
       " 'seasoning': 251,\n",
       " 'flavorful': 252,\n",
       " 'found': 253,\n",
       " 'kind': 254,\n",
       " 'keurig': 255,\n",
       " 'flavored': 256,\n",
       " 'work': 257,\n",
       " 'protein': 258,\n",
       " 'bitter': 259,\n",
       " 'snacks': 260,\n",
       " 'beware': 261,\n",
       " 'french': 262,\n",
       " 'size': 263,\n",
       " 'crunchy': 264,\n",
       " 'spice': 265,\n",
       " 'pleased': 266,\n",
       " 'most': 267,\n",
       " 'dry': 268,\n",
       " 'special': 269,\n",
       " 'purchase': 270,\n",
       " 'fun': 271,\n",
       " 'disappointing': 272,\n",
       " 'variety': 273,\n",
       " 'off': 274,\n",
       " 'always': 275,\n",
       " 'beans': 276,\n",
       " 'order': 277,\n",
       " 'puppy': 278,\n",
       " 'training': 279,\n",
       " 'bit': 280,\n",
       " 'tasted': 281,\n",
       " 'simply': 282,\n",
       " 'bears': 283,\n",
       " 'delivery': 284,\n",
       " 'over': 285,\n",
       " 'thing': 286,\n",
       " 'dried': 287,\n",
       " 'olive': 288,\n",
       " 'house': 289,\n",
       " 'whole': 290,\n",
       " 'different': 291,\n",
       " 'rich': 292,\n",
       " 'flavors': 293,\n",
       " 'cans': 294,\n",
       " 'instant': 295,\n",
       " 'fine': 296,\n",
       " 'oatmeal': 297,\n",
       " 'make': 298,\n",
       " 'powder': 299,\n",
       " 'texture': 300,\n",
       " 'decent': 301,\n",
       " 'choice': 302,\n",
       " 'gf': 303,\n",
       " 'granola': 304,\n",
       " 'customer': 305,\n",
       " 'full': 306,\n",
       " 'likes': 307,\n",
       " 'brand': 308,\n",
       " 'lovers': 309,\n",
       " 'store': 310,\n",
       " 'lemon': 311,\n",
       " 'another': 312,\n",
       " 'son': 313,\n",
       " 'market': 314,\n",
       " 'never': 315,\n",
       " 'goodness': 316,\n",
       " 'delish': 317,\n",
       " 'substitute': 318,\n",
       " 'pure': 319,\n",
       " 'morning': 320,\n",
       " 'must': 321,\n",
       " 'lover': 322,\n",
       " 'heaven': 323,\n",
       " 'long': 324,\n",
       " 'crazy': 325,\n",
       " 'pepper': 326,\n",
       " 'wheat': 327,\n",
       " 'almonds': 328,\n",
       " 'gummi': 329,\n",
       " 'oh': 330,\n",
       " 'chip': 331,\n",
       " 'mountain': 332,\n",
       " 'world': 333,\n",
       " 'about': 334,\n",
       " 'day': 335,\n",
       " 'cinnamon': 336,\n",
       " 'around': 337,\n",
       " 'toy': 338,\n",
       " 'cherry': 339,\n",
       " 'espresso': 340,\n",
       " 'maple': 341,\n",
       " 'try': 342,\n",
       " 'worst': 343,\n",
       " 'now': 344,\n",
       " 'outstanding': 345,\n",
       " 'bland': 346,\n",
       " 'red': 347,\n",
       " 'fat': 348,\n",
       " 'exactly': 349,\n",
       " 'sour': 350,\n",
       " 'soda': 351,\n",
       " 'brown': 352,\n",
       " 'every': 353,\n",
       " 'yet': 354,\n",
       " 'finally': 355,\n",
       " 'waste': 356,\n",
       " 'even': 357,\n",
       " 'nut': 358,\n",
       " 'cake': 359,\n",
       " 'used': 360,\n",
       " 'were': 361,\n",
       " 'potato': 362,\n",
       " 'advertised': 363,\n",
       " 'cheap': 364,\n",
       " 'soft': 365,\n",
       " 'meal': 366,\n",
       " 'here': 367,\n",
       " 'gross': 368,\n",
       " 'pork': 369,\n",
       " 'broken': 370,\n",
       " 'got': 371,\n",
       " 'box': 372,\n",
       " 'where': 373,\n",
       " 'first': 374,\n",
       " 'bags': 375,\n",
       " 'ingredients': 376,\n",
       " 'down': 377,\n",
       " 'after': 378,\n",
       " 'canned': 379,\n",
       " 'back': 380,\n",
       " 'corn': 381,\n",
       " 'mint': 382,\n",
       " 'family': 383,\n",
       " 'same': 384,\n",
       " 'almost': 385,\n",
       " 'popchips': 386,\n",
       " 'nom': 387,\n",
       " 'terrific': 388,\n",
       " 'smells': 389,\n",
       " 'oz': 390,\n",
       " 'why': 391,\n",
       " 'cooking': 392,\n",
       " 'arrived': 393,\n",
       " 'need': 394,\n",
       " 'diet': 395,\n",
       " 'life': 396,\n",
       " 'idea': 397,\n",
       " 'hit': 398,\n",
       " 'still': 399,\n",
       " 'china': 400,\n",
       " 'ice': 401,\n",
       " 'own': 402,\n",
       " 'nasty': 403,\n",
       " 'picky': 404,\n",
       " 'starbucks': 405,\n",
       " 'bought': 406,\n",
       " 'mustard': 407,\n",
       " 'satisfied': 408,\n",
       " 'doggie': 409,\n",
       " 'dented': 410,\n",
       " 'many': 411,\n",
       " 'cracker': 412,\n",
       " 'tried': 413,\n",
       " 'apple': 414,\n",
       " 'iced': 415,\n",
       " 'chili': 416,\n",
       " 'dental': 417,\n",
       " 'crunch': 418,\n",
       " 'last': 419,\n",
       " 'mild': 420,\n",
       " 'priced': 421,\n",
       " 'other': 422,\n",
       " 'carb': 423,\n",
       " 'filling': 424,\n",
       " 'when': 425,\n",
       " 'banana': 426,\n",
       " 'think': 427,\n",
       " 'haribo': 428,\n",
       " 'mini': 429,\n",
       " 'stars': 430,\n",
       " 'addicted': 431,\n",
       " 'quite': 432,\n",
       " 'husband': 433,\n",
       " 'home': 434,\n",
       " 'recommended': 435,\n",
       " 'package': 436,\n",
       " 'option': 437,\n",
       " 'regular': 438,\n",
       " 'cream': 439,\n",
       " 'baking': 440,\n",
       " 'brownies': 441,\n",
       " 'looking': 442,\n",
       " 'dressing': 443,\n",
       " 'please': 444,\n",
       " 'chew': 445,\n",
       " 'how': 446,\n",
       " 'homemade': 447,\n",
       " 'hazelnut': 448,\n",
       " 'flour': 449,\n",
       " 'teeth': 450,\n",
       " 'chewy': 451,\n",
       " 'calorie': 452,\n",
       " 'date': 453,\n",
       " 'brew': 454,\n",
       " 'disgusting': 455,\n",
       " 'fan': 456,\n",
       " 'ordered': 457,\n",
       " 'nutritious': 458,\n",
       " 'peanuts': 459,\n",
       " 'gummy': 460,\n",
       " 'pie': 461,\n",
       " 'less': 462,\n",
       " 'favorites': 463,\n",
       " 'rocks': 464,\n",
       " 'calories': 465,\n",
       " 'grey': 466,\n",
       " 'bbq': 467,\n",
       " 'misleading': 468,\n",
       " 'cute': 469,\n",
       " 'biscuits': 470,\n",
       " 'blue': 471,\n",
       " 'noodle': 472,\n",
       " 'say': 473,\n",
       " 'everything': 474,\n",
       " 'eating': 475,\n",
       " 'orange': 476,\n",
       " 'italian': 477,\n",
       " 'miracle': 478,\n",
       " 'sticks': 479,\n",
       " 'rip': 480,\n",
       " 'soy': 481,\n",
       " 'something': 482,\n",
       " 'almond': 483,\n",
       " 'teas': 484,\n",
       " 'san': 485,\n",
       " 'liked': 486,\n",
       " 'rinds': 487,\n",
       " 'who': 488,\n",
       " 'greatest': 489,\n",
       " 'delight': 490,\n",
       " 'addicting': 491,\n",
       " 'health': 492,\n",
       " 'any': 493,\n",
       " 'company': 494,\n",
       " 'lot': 495,\n",
       " 'save': 496,\n",
       " 'earl': 497,\n",
       " 'kitty': 498,\n",
       " 'available': 499,\n",
       " 'wild': 500,\n",
       " 'fiber': 501,\n",
       " 'yes': 502,\n",
       " 'lots': 503,\n",
       " 'pods': 504,\n",
       " 'raw': 505,\n",
       " 'superb': 506,\n",
       " 'lunch': 507,\n",
       " 'vinegar': 508,\n",
       " 'aroma': 509,\n",
       " 'daughter': 510,\n",
       " 'aftertaste': 511,\n",
       " 'tree': 512,\n",
       " 'salmon': 513,\n",
       " 'newman': 514,\n",
       " 'gold': 515,\n",
       " 'simple': 516,\n",
       " 'should': 517,\n",
       " 'gourmet': 518,\n",
       " 'delightful': 519,\n",
       " 'earth': 520,\n",
       " 'top': 521,\n",
       " 'pancakes': 522,\n",
       " 'bean': 523,\n",
       " 'english': 524,\n",
       " 'raspberry': 525,\n",
       " 'wish': 526,\n",
       " 'beautiful': 527,\n",
       " 'stevia': 528,\n",
       " 'says': 529,\n",
       " 'bones': 530,\n",
       " 'received': 531,\n",
       " 'wanted': 532,\n",
       " 'thin': 533,\n",
       " 'live': 534,\n",
       " 'bay': 535,\n",
       " 'original': 536,\n",
       " 'surprisingly': 537,\n",
       " 'thanks': 538,\n",
       " 'ounce': 539,\n",
       " 'weight': 540,\n",
       " 'smell': 541,\n",
       " 'salad': 542,\n",
       " 'bran': 543,\n",
       " 'sure': 544,\n",
       " 'satisfying': 545,\n",
       " 'curry': 546,\n",
       " 'lipton': 547,\n",
       " 'goes': 548,\n",
       " 'highly': 549,\n",
       " 'melted': 550,\n",
       " 'products': 551,\n",
       " 'impressed': 552,\n",
       " 'rock': 553,\n",
       " 'large': 554,\n",
       " 'extract': 555,\n",
       " 'mango': 556,\n",
       " 'pizza': 557,\n",
       " 'pb': 558,\n",
       " 'pet': 559,\n",
       " 'things': 560,\n",
       " 'sea': 561,\n",
       " 'lovely': 562,\n",
       " 'raisins': 563,\n",
       " 'plastic': 564,\n",
       " 'francisco': 565,\n",
       " 'grain': 566,\n",
       " 'dont': 567,\n",
       " 'average': 568,\n",
       " 'thought': 569,\n",
       " 'cost': 570,\n",
       " 'clean': 571,\n",
       " 'change': 572,\n",
       " 'strawberry': 573,\n",
       " 'plus': 574,\n",
       " 'plain': 575,\n",
       " 'crispy': 576,\n",
       " 'packs': 577,\n",
       " 'meh': 578,\n",
       " 'extremely': 579,\n",
       " 'extra': 580,\n",
       " 'thank': 581,\n",
       " 'caramel': 582,\n",
       " 'omg': 583,\n",
       " 'chocolates': 584,\n",
       " 'basket': 585,\n",
       " 'jelly': 586,\n",
       " 'kid': 587,\n",
       " 'beer': 588,\n",
       " 'jam': 589,\n",
       " 'winner': 590,\n",
       " 'away': 591,\n",
       " 'description': 592,\n",
       " 'expiration': 593,\n",
       " 'year': 594,\n",
       " 'vegan': 595,\n",
       " 'kashi': 596,\n",
       " 'formula': 597,\n",
       " 'cherries': 598,\n",
       " 'bacon': 599,\n",
       " 'plant': 600,\n",
       " 'addition': 601,\n",
       " 'fish': 602,\n",
       " 'kona': 603,\n",
       " 'summer': 604,\n",
       " 'kit': 605,\n",
       " 'wine': 606,\n",
       " 'artificial': 607,\n",
       " 'bargain': 608,\n",
       " 'magic': 609,\n",
       " 'country': 610,\n",
       " 'stash': 611,\n",
       " 'rub': 612,\n",
       " 'star': 613,\n",
       " 'us': 614,\n",
       " 'warning': 615,\n",
       " 'pretzels': 616,\n",
       " 'contains': 617,\n",
       " 'totally': 618,\n",
       " 'quickly': 619,\n",
       " 'crystal': 620,\n",
       " 'worked': 621,\n",
       " 'brownie': 622,\n",
       " 'dessert': 623,\n",
       " 'replacement': 624,\n",
       " 'needed': 625,\n",
       " 'bite': 626,\n",
       " 'agave': 627,\n",
       " 'tully': 628,\n",
       " 'needs': 629,\n",
       " 'actually': 630,\n",
       " 'stores': 631,\n",
       " 'roasted': 632,\n",
       " 'source': 633,\n",
       " 'handy': 634,\n",
       " 'expired': 635,\n",
       " 'cold': 636,\n",
       " 'toffee': 637,\n",
       " 'gone': 638,\n",
       " 'coffe': 639,\n",
       " 'tart': 640,\n",
       " 'been': 641,\n",
       " 'movie': 642,\n",
       " 'described': 643,\n",
       " 'pictured': 644,\n",
       " 'smaller': 645,\n",
       " 'medium': 646,\n",
       " 'caribou': 647,\n",
       " 'mom': 648,\n",
       " 'those': 649,\n",
       " 'crack': 650,\n",
       " 'everyday': 651,\n",
       " 'loose': 652,\n",
       " 'grass': 653,\n",
       " 'ground': 654,\n",
       " 'classic': 655,\n",
       " 'convenience': 656,\n",
       " 'unique': 657,\n",
       " 'kick': 658,\n",
       " 'darn': 659,\n",
       " 'definitely': 660,\n",
       " 'muffins': 661,\n",
       " 'nutrition': 662,\n",
       " 'keeps': 663,\n",
       " 'strange': 664,\n",
       " 'authentic': 665,\n",
       " 'msg': 666,\n",
       " 'enjoyed': 667,\n",
       " 'mints': 668,\n",
       " 'wife': 669,\n",
       " 'recipe': 670,\n",
       " 'name': 671,\n",
       " 'twinings': 672,\n",
       " 'baked': 673,\n",
       " 'weird': 674,\n",
       " 'toddler': 675,\n",
       " 'puck': 676,\n",
       " 'smart': 677,\n",
       " 'people': 678,\n",
       " 'pill': 679,\n",
       " 'hour': 680,\n",
       " 'half': 681,\n",
       " 'party': 682,\n",
       " 'quaker': 683,\n",
       " 'foods': 684,\n",
       " 'pudding': 685,\n",
       " 'want': 686,\n",
       " 'slightly': 687,\n",
       " 'steak': 688,\n",
       " 'two': 689,\n",
       " 'friendly': 690,\n",
       " 'edible': 691,\n",
       " 'true': 692,\n",
       " 'sodium': 693,\n",
       " 'shipment': 694,\n",
       " 'huge': 695,\n",
       " 'start': 696,\n",
       " 'tomato': 697,\n",
       " 'cheesy': 698,\n",
       " 'making': 699,\n",
       " 'sick': 700,\n",
       " 'picture': 701,\n",
       " 'though': 702,\n",
       " 'tummy': 703,\n",
       " 'nectar': 704,\n",
       " 'second': 705,\n",
       " 'senseo': 706,\n",
       " 'leaf': 707,\n",
       " 'paste': 708,\n",
       " 'umm': 709,\n",
       " 'years': 710,\n",
       " 'berry': 711,\n",
       " 'ramen': 712,\n",
       " 'blueberry': 713,\n",
       " 'non': 714,\n",
       " 'seller': 715,\n",
       " 'incredible': 716,\n",
       " 'bone': 717,\n",
       " 'catnip': 718,\n",
       " 'man': 719,\n",
       " 'tips': 720,\n",
       " 'jack': 721,\n",
       " 'perfectly': 722,\n",
       " 'take': 723,\n",
       " 'acid': 724,\n",
       " 'herbal': 725,\n",
       " 'maybe': 726,\n",
       " 'garlic': 727,\n",
       " 'pieces': 728,\n",
       " 'problem': 729,\n",
       " 'their': 730,\n",
       " 'keep': 731,\n",
       " 'glad': 732,\n",
       " 'staple': 733,\n",
       " 'brands': 734,\n",
       " 'creamy': 735,\n",
       " 'cet': 736,\n",
       " 'lime': 737,\n",
       " 'sooo': 738,\n",
       " 'give': 739,\n",
       " 'pecan': 740,\n",
       " 'mouth': 741,\n",
       " 'fog': 742,\n",
       " 'seed': 743,\n",
       " 'looks': 744,\n",
       " 'rawhide': 745,\n",
       " 'versatile': 746,\n",
       " 'heavenly': 747,\n",
       " 'short': 748,\n",
       " 'sesame': 749,\n",
       " 'truffle': 750,\n",
       " 'add': 751,\n",
       " 'liver': 752,\n",
       " 'peach': 753,\n",
       " 'help': 754,\n",
       " 'interesting': 755,\n",
       " 'wonderfully': 756,\n",
       " 'truly': 757,\n",
       " 'meat': 758,\n",
       " 'dinner': 759,\n",
       " 'tuna': 760,\n",
       " 'absolute': 761,\n",
       " 'microwave': 762,\n",
       " 'ones': 763,\n",
       " 'surprise': 764,\n",
       " 'style': 765,\n",
       " 'pamela': 766,\n",
       " 'close': 767,\n",
       " 'premium': 768,\n",
       " 'busy': 769,\n",
       " 'bottle': 770,\n",
       " 'beverage': 771,\n",
       " 'stomach': 772,\n",
       " 'zico': 773,\n",
       " 'everyone': 774,\n",
       " 'damaged': 775,\n",
       " 'superior': 776,\n",
       " 'boxes': 777,\n",
       " 'disappointment': 778,\n",
       " 'scrumptious': 779,\n",
       " 'hips': 780,\n",
       " 'prefer': 781,\n",
       " 'guilt': 782,\n",
       " 'hair': 783,\n",
       " 'yuk': 784,\n",
       " 'joe': 785,\n",
       " 'saver': 786,\n",
       " 'shampoo': 787,\n",
       " 'experience': 788,\n",
       " 'spices': 789,\n",
       " 'pg': 790,\n",
       " 'liquid': 791,\n",
       " 'fruity': 792,\n",
       " 'dr': 793,\n",
       " 'helps': 794,\n",
       " 'wolfgang': 795,\n",
       " 'know': 796,\n",
       " 'shipped': 797,\n",
       " 'gotta': 798,\n",
       " 'count': 799,\n",
       " 'vegetarian': 800,\n",
       " 'pleasant': 801,\n",
       " 'machine': 802,\n",
       " 'tasteless': 803,\n",
       " 'hate': 804,\n",
       " 'mess': 805,\n",
       " 'fair': 806,\n",
       " 'daily': 807,\n",
       " 'else': 808,\n",
       " 'com': 809,\n",
       " 'pricing': 810,\n",
       " 'allergy': 811,\n",
       " 'candies': 812,\n",
       " 'bulk': 813,\n",
       " 'dream': 814,\n",
       " 'delicous': 815,\n",
       " 'bites': 816,\n",
       " 'sweetener': 817,\n",
       " 'finicky': 818,\n",
       " 'gets': 819,\n",
       " 'cafe': 820,\n",
       " 'tiny': 821,\n",
       " 'problems': 822,\n",
       " 'hands': 823,\n",
       " 'job': 824,\n",
       " 'she': 825,\n",
       " 'gave': 826,\n",
       " 'cal': 827,\n",
       " 'kcup': 828,\n",
       " 'bonsai': 829,\n",
       " 'feel': 830,\n",
       " 'christmas': 831,\n",
       " 'babies': 832,\n",
       " 'days': 833,\n",
       " 'pick': 834,\n",
       " 'advertising': 835,\n",
       " 'mediocre': 836,\n",
       " 'balance': 837,\n",
       " 'assortment': 838,\n",
       " 'soooo': 839,\n",
       " 'doggy': 840,\n",
       " 'gravy': 841,\n",
       " 'effective': 842,\n",
       " 'cashews': 843,\n",
       " 'golden': 844,\n",
       " 'anywhere': 845,\n",
       " 'grains': 846,\n",
       " 'selection': 847,\n",
       " 'caviar': 848,\n",
       " 'yay': 849,\n",
       " 'pancake': 850,\n",
       " 'side': 851,\n",
       " 'lamb': 852,\n",
       " 'leaves': 853,\n",
       " 'maxwell': 854,\n",
       " 'enjoy': 855,\n",
       " 'yogi': 856,\n",
       " 'watch': 857,\n",
       " 'prunes': 858,\n",
       " 'nutty': 859,\n",
       " 'pleasure': 860,\n",
       " 'surprised': 861,\n",
       " 'solid': 862,\n",
       " 'crisp': 863,\n",
       " 'theater': 864,\n",
       " 'lab': 865,\n",
       " 'raisin': 866,\n",
       " 'bisquick': 867,\n",
       " 'added': 868,\n",
       " 'gummies': 869,\n",
       " 'affordable': 870,\n",
       " 'latte': 871,\n",
       " 'caffeine': 872,\n",
       " 'approved': 873,\n",
       " 'month': 874,\n",
       " 'odd': 875,\n",
       " 'coco': 876,\n",
       " 'tangy': 877,\n",
       " 'awsome': 878,\n",
       " 'stop': 879,\n",
       " 'cheez': 880,\n",
       " 'dissapointed': 881,\n",
       " 'care': 882,\n",
       " 'tassimo': 883,\n",
       " 'mother': 884,\n",
       " 'northern': 885,\n",
       " 'few': 886,\n",
       " 'eh': 887,\n",
       " 'wellness': 888,\n",
       " 'fake': 889,\n",
       " 'costco': 890,\n",
       " 'grape': 891,\n",
       " 'curls': 892,\n",
       " 'nature': 893,\n",
       " 'planet': 894,\n",
       " 'power': 895,\n",
       " 'watery': 896,\n",
       " 'pockets': 897,\n",
       " 'false': 898,\n",
       " 'stay': 899,\n",
       " 'remember': 900,\n",
       " 'ears': 901,\n",
       " 'before': 902,\n",
       " 'complete': 903,\n",
       " 'cheddar': 904,\n",
       " 'anything': 905,\n",
       " 'waffles': 906,\n",
       " 'folgers': 907,\n",
       " 'apples': 908,\n",
       " 'onion': 909,\n",
       " 'standard': 910,\n",
       " 'thai': 911,\n",
       " 'wake': 912,\n",
       " 'then': 913,\n",
       " 'he': 914,\n",
       " 'paws': 915,\n",
       " 'mixed': 916,\n",
       " 'de': 917,\n",
       " 'went': 918,\n",
       " 'tough': 919,\n",
       " 'switch': 920,\n",
       " 'recommend': 921,\n",
       " 'donut': 922,\n",
       " 'hibiscus': 923,\n",
       " 'changed': 924,\n",
       " 'boost': 925,\n",
       " 'robust': 926,\n",
       " 'put': 927,\n",
       " 'kitties': 928,\n",
       " 'buyer': 929,\n",
       " 'breath': 930,\n",
       " 'buying': 931,\n",
       " 'creamer': 932,\n",
       " 'pops': 933,\n",
       " 'packaged': 934,\n",
       " 'tomatoes': 935,\n",
       " 'covered': 936,\n",
       " 'molasses': 937,\n",
       " 'flavoring': 938,\n",
       " 'five': 939,\n",
       " 'sensitive': 940,\n",
       " 'soothing': 941,\n",
       " 'said': 942,\n",
       " 'condition': 943,\n",
       " 'vita': 944,\n",
       " 'diamond': 945,\n",
       " 'cardboard': 946,\n",
       " 'fix': 947,\n",
       " 'waffle': 948,\n",
       " 'ingredient': 949,\n",
       " 'birthday': 950,\n",
       " 'bigelow': 951,\n",
       " 'cool': 952,\n",
       " 'chaser': 953,\n",
       " 'sticky': 954,\n",
       " 'salsa': 955,\n",
       " 'safe': 956,\n",
       " 'altoids': 957,\n",
       " 'naturals': 958,\n",
       " 'instead': 959,\n",
       " 'sf': 960,\n",
       " 'stick': 961,\n",
       " 'packages': 962,\n",
       " 'strips': 963,\n",
       " 'amazingly': 964,\n",
       " 'ghee': 965,\n",
       " 'sardines': 966,\n",
       " 'marinade': 967,\n",
       " 'bed': 968,\n",
       " 'hint': 969,\n",
       " 'seems': 970,\n",
       " 'increase': 971,\n",
       " 'childhood': 972,\n",
       " 'doggies': 973,\n",
       " 'usa': 974,\n",
       " 'soups': 975,\n",
       " 'chia': 976,\n",
       " 'slow': 977,\n",
       " 'warm': 978,\n",
       " 'puffs': 979,\n",
       " 'taffy': 980,\n",
       " 'look': 981,\n",
       " 'fav': 982,\n",
       " 'outrageous': 983,\n",
       " 'perfection': 984,\n",
       " 'healthier': 985,\n",
       " 'pot': 986,\n",
       " 'friend': 987,\n",
       " 'cacao': 988,\n",
       " 'bottles': 989,\n",
       " 'egg': 990,\n",
       " 'secret': 991,\n",
       " 'night': 992,\n",
       " 'seasonings': 993,\n",
       " 'macadamia': 994,\n",
       " 'buddy': 995,\n",
       " 'indeed': 996,\n",
       " 'veggie': 997,\n",
       " 'believe': 998,\n",
       " 'fudge': 999,\n",
       " 'barley': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summ_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='training_loss')\n",
    "pyplot.plot(history.history['val_loss'], label='testing_loss')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On Y axis we have loss for training and testing  and on x axis we have number of epochs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference : Greedy Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the feature vector\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs_final, state_hfinal, state_cfinal])\n",
    "\n",
    "# Decoder setup\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
    "\n",
    "#Embedding at decoder side\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) \n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "#attention Model\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# A dense softmax layer\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(input_seq):\n",
    "    # Encoder output\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Generate an empty summary sequence of length 1\n",
    "    summ_seq = np.zeros((1,1))\n",
    "    \n",
    "    # Initialize the first word with our start token\n",
    "    summ_seq[0,0] = summ_word_index['sostok']\n",
    "    \n",
    "    \n",
    "    generated_summary = ''\n",
    "    while True:\n",
    "        output_tokens, h, c = decoder_model.predict([summ_seq] + [e_out,e_h,e_c])\n",
    "        \n",
    "        # Predicted token\n",
    "        predicted_token_index = np.argmax(output_tokens[0,-1,:])\n",
    "        predicted_token = summ_index_word[predicted_token_index]\n",
    "        \n",
    "        if predicted_token != 'eostok':\n",
    "            generated_summary += ' ' + predicted_token \n",
    "        \n",
    "        # break if we reached the max length or received our end token\n",
    "        if predicted_token == 'eostok' or len(generated_summary.split()) >= (max_summary_len -1):\n",
    "            break\n",
    "            \n",
    "        # Update the summary seq\n",
    "        summ_seq = np.zeros((1,1))\n",
    "        summ_seq[0,0] = predicted_token_index\n",
    "        \n",
    "        # update internal states\n",
    "        e_h, e_c= h,c\n",
    "        \n",
    "    return generated_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=summ_word_index['sostok']) and i!=summ_word_index['eostok']):\n",
    "            newString=newString+summ_index_word[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+text_index_word[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: got great course good belgian chocolates better \n",
      "Original summary: would like to give it stars but \n",
      "Projected summary:  great\n",
      "\n",
      "\n",
      "Text: one best flavored coffees tried usually like flavored coffees one great serve company love \n",
      "Original summary: delicious \n",
      "Projected summary:  best coffee\n",
      "\n",
      "\n",
      "Text: salt separate area pain makes hard regulate salt putting like salt go ahead get product \n",
      "Original summary: tastes ok packaging \n",
      "Projected summary:  great\n",
      "\n",
      "\n",
      "Text: really like product super easy order online delivered much cheaper buying gas station stocking good long drives \n",
      "Original summary: turkey jerky is great \n",
      "Projected summary:  great\n",
      "\n",
      "\n",
      "Text: best salad dressing delivered promptly quantities last vidalia onion dressing compares made oak hill farms sometimes find costco order front door want even orders cut shipping costs \n",
      "Original summary: my favorite salad dressing \n",
      "Projected summary:  great\n",
      "\n",
      "\n",
      "Text: think sitting around warehouse long time took long time send got tea tasted like cardboard red rasberry leaf tea know supposed taste like \n",
      "Original summary: stale \n",
      "Projected summary:  great coffee\n",
      "\n",
      "\n",
      "Text: love different kinds tea one good others want better taste make black tea put little lemon juice big fan individually wrapped teabags either make much trash put landfills \n",
      "Original summary: has weird taste \n",
      "Projected summary:  great tea\n",
      "\n",
      "\n",
      "Text: always perfect snack dog loves knows exactly starts ask time evening gets greenie snack thank excellent product fast delivery \n",
      "Original summary: greenies buddy treat \n",
      "Projected summary:  great\n",
      "\n",
      "\n",
      "Text: delicious coffee cake ever moist absolutely addictive \n",
      "Original summary: yum \n",
      "Projected summary:  best coffee\n",
      "\n",
      "\n",
      "Text: liked coffee much subscribing dark rich smooth \n",
      "Original summary: makes great cup of java \n",
      "Projected summary:  best coffee\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    print(\"Text:\",seq2text(x_tr[i]))\n",
    "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
    "    print(\"Projected summary:\",generate_summary(x_tr[i].reshape(1,max_text_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Ww will evaluate our Generated summary with the help of ROUGE Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge \n",
    "rouge = Rouge()\n",
    "for i in range(0,10):\n",
    "    \n",
    "    hypothesis = generate_summary(x_tr[i].reshape(1,max_text_len))\n",
    "    reference = seq2summary(y_tr[i])\n",
    "    scores = rouge.get_scores(hypothesis, reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'rouge-1': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.0, 'p': 0.0, 'r': 0.0}}]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implimentation of <b>pointer generator networks</b> for better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implimenting <b>Beam Search</b> instead of Greedy search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
