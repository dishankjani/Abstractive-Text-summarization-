{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "print((tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset PreProcessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = pd.read_csv(\"Reviews.csv\",nrows=100000) #We will use the dataset of Amazon Fine food Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                        0\n",
       "ProductId                 0\n",
       "UserId                    0\n",
       "ProfileName               4\n",
       "HelpfulnessNumerator      0\n",
       "HelpfulnessDenominator    0\n",
       "Score                     0\n",
       "Time                      0\n",
       "Summary                   2\n",
       "Text                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = text_data.dropna() #remove Missing values\n",
    "text_data.drop_duplicates(subset=['Text'],inplace=True)#dropping duplicayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing unwanted features\n",
    "\n",
    "text_data = text_data.dropna()\n",
    "text_data = text_data.drop(['Id','ProductId','UserId','ProfileName','HelpfulnessNumerator','HelpfulnessDenominator',\n",
    "                        'Score','Time'], 1)\n",
    "text_data = text_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Summary                                               Text\n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...\n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...\n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...\n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...\n",
       "4            Great taffy  Great taffy at a great price.  There was a wid..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review # 1\n",
      "Good Quality Dog Food\n",
      "I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.\n",
      "\n",
      "Review # 2\n",
      "Not as Advertised\n",
      "Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".\n",
      "\n",
      "Review # 3\n",
      "\"Delight\" says it all\n",
      "This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with powdered sugar.  And it is a tiny mouthful of heaven.  Not too chewy, and very flavorful.  I highly recommend this yummy treat.  If you are familiar with the story of C.S. Lewis' \"The Lion, The Witch, and The Wardrobe\" - this is the treat that seduces Edmund into selling out his Brother and Sisters to the Witch.\n",
      "\n",
      "Review # 4\n",
      "Cough Medicine\n",
      "If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The flavor is very medicinal.\n",
      "\n",
      "Review # 5\n",
      "Great taffy\n",
      "Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"Review #\",i+1)\n",
    "    print(text_data.Summary[i])\n",
    "    print(text_data.Text[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we must remove the unwanted characters using regular expressions(re) and remove the stop words \n",
    "#We must replace the contractions with it's full words \n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "def text_processing(text,num):\n",
    "    newString = text.lower()\n",
    "    newString = BeautifulSoup(newString, \"lxml\").text\n",
    "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
    "    newString = re.sub('\"','', newString)\n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
    "    newString = re.sub('[m]{2,}', 'mm', newString)\n",
    "    if(num==0):\n",
    "        tokens = [w for w in newString.split() if not w in stop_words]\n",
    "    else:\n",
    "        tokens=newString.split()\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>1:                                                 #removing short word\n",
    "            long_words.append(i)   \n",
    "    return (\" \".join(long_words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dishank/anaconda3/lib/python3.7/site-packages/bs4/__init__.py:389: UserWarning: \"http://www.amazon.com/gp/product/b007i7yygy/ref=cm_cr_rev_prod_title\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    }
   ],
   "source": [
    "#cleaning the Dataset text and summaries and save the updated reviews in clean_text and clean_summaries list\n",
    "            \n",
    "clean_summaries = []\n",
    "for summary in text_data.Summary:\n",
    "    clean_summaries.append(text_processing(summary,1))\n",
    "\n",
    "clean_texts = []\n",
    "for text in text_data.Text:\n",
    "    clean_texts.append(text_processing(text,0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_summary_length = 8\n",
    "max_text_length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Review # 1\n",
      "good quality dog food\n",
      "bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better\n",
      "\n",
      "Clean Review # 2\n",
      "not as advertised\n",
      "product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo\n",
      "\n",
      "Clean Review # 3\n",
      "delight says it all\n",
      "confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch\n",
      "\n",
      "Clean Review # 4\n",
      "cough medicine\n",
      "looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal\n",
      "\n",
      "Clean Review # 5\n",
      "great taffy\n",
      "great taffy great price wide assortment yummy taffy delivery quick taffy lover deal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"Clean Review #\",i+1)\n",
    "    print(clean_summaries[i])\n",
    "    print(clean_texts[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good quality dog food', 'not as advertised', 'delight says it all', 'cough medicine', 'great taffy']\n"
     ]
    }
   ],
   "source": [
    "print(clean_summaries[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data['clean_texts']=clean_texts\n",
    "text_data['clean_summaries']=clean_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data.replace('', np.nan, inplace=True)\n",
    "text_data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_word_count = []\n",
    "summary_word_count = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in text_data['clean_texts']:\n",
    "      text_word_count.append(len(i.split()))\n",
    "\n",
    "for i in text_data['clean_summaries']:\n",
    "      summary_word_count.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'texts':text_word_count, 'summary':summary_word_count})\n",
    "\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation Of The Vocabulary and Tokenization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9424907471335922\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "for i in text_data['clean_summaries']:\n",
    "    if(len(i.split())<=8):\n",
    "        cnt=cnt+1\n",
    "print(cnt/len(text_data['clean_summaries']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_texts =np.array(text_data['clean_texts'])\n",
    "clean_summaries=np.array(text_data['clean_summaries'])\n",
    "\n",
    "short_text=[]\n",
    "short_summary=[]\n",
    "\n",
    "for i in range(len(clean_texts)):\n",
    "    if(len(clean_summaries[i].split())<=max_summary_length and len(clean_texts[i].split())<=max_text_length):\n",
    "        short_text.append(clean_texts[i])\n",
    "        short_summary.append(clean_summaries[i])\n",
    "        \n",
    "df=pd.DataFrame({'text':short_text,'summary':short_summary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORD EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_shape=np.shape(short_text[0])\n",
    "de_shape=np.shape(short_summary[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we find that only 5.35% of words are missing in CN embedding vector which is much better then th GloVe vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspection of Text and Summaries and Handling  Unknown Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'text':short_text,'summary':short_summary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    " #we put <SOS> and <EOS> text before and at the end of each summary\n",
    "\n",
    "df['summary'] = df['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as tk\n",
    "tk.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TOKENIZATION</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x-text y-sum tr-train val-value\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sum_train,sum_value,text_train,text_value=train_test_split(np.array(df['text']),np.array(df['summary']),test_size=0.1,random_state=0,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>For Text</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This may take some time\n",
    "text_tokenizer = Tokenizer() \n",
    "text_tokenizer.fit_on_texts(list(sum_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Handling Rare Words</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh=4\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 66.12339930151339\n",
      "Total Coverage of rare words: 2.953684513790566\n"
     ]
    }
   ],
   "source": [
    "for key,value in text_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8440\n"
     ]
    }
   ],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "text_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "text_tokenizer.fit_on_texts(list(text_train))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "text_train_seq    = text_tokenizer.texts_to_sequences(text_train) \n",
    "text_value_seq   =   text_tokenizer.texts_to_sequences(text_value)\n",
    "\n",
    "#padding zero upto maximum length\n",
    "text_train    =   pad_sequences(text_train_seq,  maxlen=max_text_length, padding='post')\n",
    "text_value   =   pad_sequences(text_value_seq, maxlen=max_text_length, padding='post')\n",
    "\n",
    "#size of vocabulary ( +1 for padding token)\n",
    "text_vocab   =  text_tokenizer.num_words + 1\n",
    "print(text_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>For Summary</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "sum_tokenizer = Tokenizer()   \n",
    "sum_tokenizer.fit_on_texts(list(sum_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 73.0400224800289\n",
      "Total Coverage of rare words: 3.943610061734083\n"
     ]
    }
   ],
   "source": [
    "thresh=6\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in sum_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "sum_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "sum_tokenizer.fit_on_texts(list(sum_train))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "sum_train_seq    =   sum_tokenizer.texts_to_sequences(sum_train) \n",
    "sum_value_seq   =   sum_tokenizer.texts_to_sequences(sum_value) \n",
    "\n",
    "#padding zero upto maximum length\n",
    "sum_train    =   pad_sequences(sum_train_seq, maxlen=max_summary_length, padding='post')\n",
    "sum_value   =   pad_sequences(sum_value_seq, maxlen=max_summary_length, padding='post')\n",
    "\n",
    "#size of vocabulary\n",
    "summary_vocab  =   sum_tokenizer.num_words +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6717\n"
     ]
    }
   ],
   "source": [
    "print(summary_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove words that contain start and end tag only\n",
    "\n",
    "ind=[]\n",
    "for i in range(len(sum_train)):\n",
    "    cnt=0\n",
    "    for j in sum_train[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "sum_train=np.delete(sum_train,ind, axis=0)\n",
    "text_train=np.delete(text_train,ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buliding The Modal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For encoder : Bidirectional LSTM Will be used <br>\n",
    "Decoder : Bidirectional LSTM Blocks Will be used<br>\n",
    "For Better Precision <b>Bahadanu Attention Modal</b> is used for better performance of long text<br>\n",
    "At Decoding Layer Beam Search is used as Inference<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.python.layers.core import Dense\n",
    "from tensorflow.python.ops.rnn_cell_impl import _zero_state_tensors\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensorflow Placeholders\n",
    "\n",
    "\n",
    "def placeholder_input():\n",
    "    '''Create palceholders for inputs to the model'''\n",
    "    \n",
    "    input_data = tf.placeholder(tf.int32, [None, None], name='input')\n",
    "    targets = tf.placeholder(tf.int32, [None, None], name='targets')\n",
    "    lr = tf.placeholder(tf.float32, name='learning_rate')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    summary_length = tf.placeholder(tf.int32, (None,), name='summary_length')\n",
    "    max_summary_length = tf.reduce_max(summary_length, name='max_dec_len')\n",
    "    text_length = tf.placeholder(tf.int32, (None,), name='text_length')\n",
    "\n",
    "    return input_data, targets, lr, keep_prob, summary_length, max_summary_length, text_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "num_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_block(lstm_size, keep_prob):\n",
    "        \"\"\"Creates LSTM block\n",
    "        \"\"\"\n",
    "        cell = tf.nn.rnn_cell.LSTMCell(lstm_size ,  initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n",
    "        cell = tf.nn.rnn_cell.DropoutWrapper(cell, input_keep_prob=keep_prob)\n",
    "        return cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to do sentence padding so that each sentence of a batch entering encoder is of same length\n",
    "def sentence_padding(batch_text):\n",
    "\n",
    "    max_sentence = max([len(sentence) for sentence in batch_text])\n",
    "    batch_value =  [sentence + [vocab_en['<PAD>']] * (max_sentence - len(sentence)) \n",
    "                    for sentence in sentence_batch]\n",
    "    return batch_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(summaries, texts, batch_size):\n",
    "    \"\"\"Batch summaries, texts, and the lengths of their sentences together\"\"\"\n",
    "    for batch_i in range(0, len(texts)//batch_size):\n",
    "        start_i = batch_i * batch_size\n",
    "        summaries_batch = summaries[start_i:start_i + batch_size]\n",
    "        texts_batch = texts[start_i:start_i + batch_size]\n",
    "        pad_summaries_batch = np.array(pad_sentence_batch(summaries_batch))\n",
    "        pad_texts_batch = np.array(pad_sentence_batch(texts_batch))\n",
    "        \n",
    "        # Need the lengths for the _lengths parameters\n",
    "        pad_summaries_lengths = []\n",
    "        for summary in pad_summaries_batch:\n",
    "            pad_summaries_lengths.append(len(summary))\n",
    "        \n",
    "        pad_texts_lengths = []\n",
    "        for text in pad_texts_batch:\n",
    "            pad_texts_lengths.append(len(text))\n",
    "        \n",
    "        yield pad_summaries_batch, pad_texts_batch, pad_summaries_lengths, pad_texts_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Creation Of bidirectional LSTM Encoder</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout(x,rate,training):\n",
    "    return tf.cond(tf_train,\n",
    "                    lambda: tf.nn.dropout(x,rate=0.3),\n",
    "                    lambda: x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embd_text = tf.nn.embedding_lookup(tf_embd, tf_text)\n",
    "\n",
    "#embd_text = dropout(embd_text,rate=0.3,training=tf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#S = tf.shape(embd_text)[1] #text sequence length\n",
    "#N = tf.shape(embd_text)[0] #batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before going to the decoder the text coming from Encoder is processed\n",
    "def process_encoding_input(target_data, vocab_en, batch_size):\n",
    "    '''Remove the last word id from each batch and concat the <GO> to the begining of each batch'''\n",
    "    \n",
    "    ending = tf.strided_slice(target_data, [0, 0], [batch_size, -1], [1, 1])\n",
    "    decoder_input = tf.concat([tf.fill([batch_size, 1], vocab_en['<GO>']), ending], 1)\n",
    "\n",
    "    return decoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(lstm_size, sequence_length,encoder_layers, lstm_inputs, keep_prob):\n",
    "    \n",
    "    for layer in range(num_layers):\n",
    "        with tf.variable_scope('encoder_{}'.format(layer)):\n",
    "\n",
    "            #Defining the forwaard and Backward cell for Bidirectional RNN\n",
    "            fw_cell = lstm_block(lstm_size // 2,keep_prob)\n",
    "            bw_cell = lstm_block(lstm_size // 2,  keep_prob) \n",
    "    \n",
    "    \n",
    "            encoder_output, encoder_state = tf.nn.bidirectional_dynamic_rnn(fw_cell, \n",
    "                                                                    bw_cell, \n",
    "                                                                    lstm_inputs,\n",
    "                                                                    sequence_length,\n",
    "                                                                    dtype=tf.float32)\n",
    "    # Join outputs since we are using a bidirectional RNN\n",
    "    encoder_output = tf.concat(encoder_output,2)\n",
    "    \n",
    "    return encoder_output, encoder_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Creation of Bidirectional Decoder</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_decoder(glove_embeddings,dec_embed_input, summary_length, decoder_cell, initial_state, output_layer, \n",
    "                            vocab_size, max_summary_length):\n",
    "\n",
    "    eos_id = tf.cast(vocab_en[eos], tf.int32)\n",
    "    \n",
    "    training_sampler = tfa.seq2seq.ScheduledEmbeddingTrainingSampler(\n",
    "                    sampling_probability=0.5,\n",
    "                    time_major=False)\n",
    "    \n",
    "    #Basic decoder\n",
    "    training_decoder = tfa.seq2seq.BasicDecoder(decoder_cell,\n",
    "                                                       training_sampler,\n",
    "                                                       output_layer) \n",
    "    \n",
    "    t_logits,_ ,_ = tfa.seq2seq.dynamic_decode(training_decoder,\n",
    "                                  output_time_major=False,\n",
    "                                  impute_finished=True,\n",
    "                                  maximum_iterations=max_summary_length)\n",
    "\n",
    "    \n",
    "    return training_decoder\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_modal(encoder_output , decoder_cell , lstm_size , text_lengths,alignment_history = False):\n",
    "    \n",
    "    #context\n",
    "        attention_context = tfa.seq2seq.BahdanauAttention(num_units=lstm_size,\n",
    "                                                                   memory=encoder_output,\n",
    "                                                                   memory_sequence_length=text_lengths,\n",
    "                                                                   name='BahdanauAttention')\n",
    "        \n",
    "#target\n",
    "        att_cell = tfa.seq2seq.AttentionWrapper(cell=decoder_cell,\n",
    "                                                   attention_mechanism=attention_context,\n",
    "                                                   attention_layer_size=None,\n",
    "                                                   output_attention=False,\n",
    "                                                   alignment_history=alignment_history)\n",
    "        \n",
    "        return att_cell\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_Search(word_embeddings,start_token ,end_tokens, decoder_cell, initial_state, \n",
    "                output_layer,max_summary_length,batch_size):\n",
    "    \n",
    "        start_tokens = tf.tile(tf.constant([start_token], dtype=tf.int32), [batch_size], name='start_tokens')\n",
    "    \n",
    "        inference_helper = tfa.seq2seq.GreedyEmbeddingSampler(\n",
    "                                                                )\n",
    "                \n",
    "        inference_decoder = tfa.seq2seq.BasicDecoder(decoder_cell,\n",
    "                                                        inference_helper,\n",
    "                                                        initial_state,\n",
    "                                                        output_layer)\n",
    "                \n",
    "        inference_logits, _ , _ = tfa.seq2seq.dynamic_decode(inference_decoder,\n",
    "                                                            output_time_major=False,\n",
    "                                                            impute_finished=True,\n",
    "                                                            maximum_iterations=max_summary_length)\n",
    "        return greedy_decoder\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(dec_embed_input, glove_embeddings, encoder_output, encoder_state, vocab_size, text_length, \n",
    "            summary_length,max_summary_length, lstm_size, vocab_en, keep_prob, batch_size, num_layers):\n",
    "    \n",
    "    \n",
    "    #Define Start and end Tokens\n",
    "    start_token =  vocab_en['<GO>']\n",
    "    start_tokens= start_tokens = tf.tile(tf.constant([start_token], dtype=tf.int32), [batch_size], name='start_tokens')\n",
    "    end_token =  vocab_en['<EOS>']\n",
    "    \n",
    "    \n",
    "    for layer in range(num_layers):\n",
    "        with tf.variable_scope(format(layer)):\n",
    "            lstm = tf.nn.rnn_cell.LSTMCell(lstm_size,\n",
    "                                           initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n",
    "            decoder_cell = tf.nn.rnn_cell.DropoutWrapper(lstm, \n",
    "                                                             input_keep_prob = keep_prob)\n",
    "    \n",
    "    output_layer = Dense(vocab_size,\n",
    "                         kernel_initializer = tf.truncated_normal_initializer(mean = 0.0, stddev=0.1))\n",
    "    \n",
    "    \n",
    "    #Attention Mechanism\n",
    "    #decoder_output = attention_modal(encoder_output , decoder_cell , lstm_size , text_length)\n",
    "    attn_mech = tfa.seq2seq.BahdanauAttention(lstm_size,\n",
    "                                                  encoder_output,\n",
    "                                                  text_length,\n",
    "                                                  normalize=False,\n",
    "                                                  name='BahdanauAttention')\n",
    "    \n",
    "    decoder_cell = tfa.seq2seq.AttentionWrapper(decoder_cell,\n",
    "                                                          attn_mech,\n",
    "                                                          lstm_size,alignment_history = False,output_attention = True,)\n",
    "    \n",
    "    \n",
    "                                                                                       \n",
    "      #Initial State of decoder will be the same as encoder_state[0]  \n",
    "    initial_state = decoder_cell.get_initial_state(inputs = None,batch_size=batch_size,dtype=tf.float32).clone(cell_state=encoder_state[0])\n",
    "\n",
    "    \n",
    "    #Training decoder Layer\n",
    "    with tf.variable_scope(\"decode\"):\n",
    "        \n",
    "        #Basic Decoding\n",
    "        trained_decoder =     training_decoder(glove_embeddings,dec_embed_input,  \n",
    "                                                  summary_length, \n",
    "                                                  decoder_cell, \n",
    "                                                  initial_state,\n",
    "                                                  output_layer,\n",
    "                                                  vocab_size, \n",
    "                                                  max_summary_length)\n",
    "        \n",
    "        \n",
    "        #Dynamic Decoding\n",
    "        training_logits,_ ,_ = tfa.seq2seq.dynamic_decode(decoder = trained_decoder,\n",
    "                            maximum_iterations = max_summary_length,\n",
    "                            swap_memory = True,\n",
    "                            scope = None,\n",
    "                            decoder_init_input= glove_embeddings,\n",
    "                            decoder_init_kwargs= {\n",
    "                                'initial_state' : initial_state,\n",
    "                                'start_tokens': start_tokens, 'end_token': end_token\n",
    "                            })\n",
    "        \n",
    "    with tf.variable_scope(\"decode\", reuse=True):\n",
    "        inference_decoder =           beam_Search(glove_embeddings,  \n",
    "                                                    start_token, \n",
    "                                                    end_token,\n",
    "                                                    decoder_cell, \n",
    "                                                    initial_state, \n",
    "                                                    output_layer,\n",
    "                                                    max_summary_length,\n",
    "                                                    batch_size)\n",
    "        #Dynamic Decoding for inference\n",
    "        inference_logits,_ ,_ = tfa.seq2seq.dynamic_decode(inference_decoder,\n",
    "                                  output_time_major=False,\n",
    "                                  impute_finished=True,\n",
    "                                  maximum_iterations=max_summary_length,parallel_iterations = 32)\n",
    "\n",
    "    return training_logits, inference_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Buliding Sequence to sequence Modal with encoder decoder architecture </h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution Of Modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as tk\n",
    "tk.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_shape=np.shape(short_text[0])\n",
    "de_shape=np.shape(short_summary[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Encoder Execution</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100  \n",
    " # Encoder\n",
    "batch_size = 50\n",
    "num_classes = 1\n",
    "epochs = 20\n",
    "learning_rate = 0.005\n",
    "clip_norm = 2.0\n",
    "encoder_inputs = Input(shape=(max_text_length,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding layer\n",
    "enc_embed_input =  Embedding(text_vocab, embedding_dim,trainable=True)(encoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder lstm layer 1\n",
    "encoder_lstm_layer1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,\n",
    "                     recurrent_dropout=0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm_layer1(enc_embed_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder lstm layer 2\n",
    "encoder_lstm_layer2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm_layer2(encoder_output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder lstm layer 3\n",
    "encoder_lstm_layer3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm_layer3(encoder_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Decoder Execution</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "#embedding layer\n",
    "dec_embed_layer = Embedding(summary_vocab, embedding_dim,trainable=True)\n",
    "dec_embed = dec_embed_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences = True, return_state = True)\n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_embed, initial_state = [state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,LSTM,Input,Activation,Add,TimeDistributed,\\\n",
    "Permute,Flatten,RepeatVector,Lambda,Multiply,Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 30, 100)\n",
      "(None, None, 100)\n",
      "(100, 30, None)\n",
      "(100, None, None)\n"
     ]
    }
   ],
   "source": [
    "decoder_outputs1 = tf.transpose(\n",
    "    decoder_outputs)\n",
    "encoder_outputs1 = tf.transpose(\n",
    "    encoder_outputs)\n",
    "print(encoder_outputs.shape)\n",
    "print(decoder_outputs.shape)\n",
    "\n",
    "print(encoder_outputs1.shape)\n",
    "print(decoder_outputs1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Attention Modal</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 30)\n"
     ]
    }
   ],
   "source": [
    "# Query-value attention of shape [batch_size, Tq, filters].\n",
    "attention = TimeDistributed(Dense(1, activation = 'tanh'))(encoder_outputs)\n",
    "attention = Flatten()(attention)\n",
    "print(attention.shape)\n",
    "attention = Multiply()([decoder_outputs1,attention])\n",
    "attention = Activation('softmax')(attention)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights shape: (batch_size, sequence_length, 1) Tensor(\"activation/Identity:0\", shape=(100, None, 30), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#context_vector, attention_weights = Attention(encoder_outputs,decoder_outputs)\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 30, 100)      844000      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 30, 100), (N 80400       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 30, 100), (N 80400       lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 100)    671700      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 30, 100), (N 80400       lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 100),  80400       embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 30, 1)        101         lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose (TensorFl [(100, None, None)]  0           lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 30)           0           time_distributed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (100, None, 30)      0           tf_op_layer_Transpose[0][0]      \n",
      "                                                                 flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (100, None, 30)      0           multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (100, None, 130)     0           lstm_3[0][0]                     \n",
      "                                                                 activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 6717)   879927      concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 2,717,328\n",
      "Trainable params: 2,717,328\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attention])\n",
    "\n",
    "#dense layer\n",
    "decoder_dense =  TimeDistributed(Dense(summary_vocab, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "# Define the model \n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, 6717)\n"
     ]
    }
   ],
   "source": [
    "print(decoder_outputs.shape)\n",
    "#model.fit( train_data_X, train_data_Y_, epochs=20, validation_split=0.2, batch_size=600, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatnation of Attention input with decoder output in another block\n",
    "\n",
    "#decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, \n",
    "                                                                 # attn_result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Modal Evaluation</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dense layer and final output is passed through softmax activation\n",
    "#decoder_dense =  TimeDistributed(Dense(summary_vocab, activation='softmax'))\n",
    "#decoder_outputs = decoder_dense(decoder_concat_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sparse Categorial Crossentropy is used for calculating loss \n",
    "#reference : https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modal will stop execute if detects negative loss\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TRAINING THE MODAL</h1><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:531 train_step  **\n        y_pred = self(x, training=True)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:927 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py:719 call\n        convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py:888 _run_internal_graph\n        output_tensors = layer(computed_tensors, **kwargs)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:927 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/merge.py:183 call\n        return self._merge_function(inputs)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/merge.py:522 _merge_function\n        return K.concatenate(inputs, axis=self.axis)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:2709 concatenate\n        return array_ops.concat([to_dense(x) for x in tensors], axis)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:180 wrapper\n        return target(*args, **kwargs)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:1606 concat\n        return gen_array_ops.concat_v2(values=values, axis=axis, name=name)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py:1189 concat_v2\n        \"ConcatV2\", values=values, axis=axis, name=name)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:744 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py:595 _create_op_internal\n        compute_device)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:3327 _create_op_internal\n        op_def=op_def)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1817 __init__\n        control_input_ops, op_def)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1657 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimension 1 in both shapes must be equal, but are 7 and 30. Shapes are [?,7] and [?,30]. for '{{node model_4/concat_layer/concat}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](model_4/lstm_8/StatefulPartitionedCall:1, model_4/additive_attention_12/MatMul, model_4/concat_layer/concat/axis)' with input shapes: [?,7,100], [?,30,100], [] and with computed input tensors: input[2] = <2>.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-198-ad7c77b6d7b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   validation_data=([text_value,sum_value[:,:-1]], \n\u001b[0;32m----> 5\u001b[0;31m                 sum_value.reshape(sum_value.shape[0],sum_value.shape[1], 1)[:,1:]))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    505\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 506\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:531 train_step  **\n        y_pred = self(x, training=True)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:927 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py:719 call\n        convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py:888 _run_internal_graph\n        output_tensors = layer(computed_tensors, **kwargs)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:927 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/merge.py:183 call\n        return self._merge_function(inputs)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/merge.py:522 _merge_function\n        return K.concatenate(inputs, axis=self.axis)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:2709 concatenate\n        return array_ops.concat([to_dense(x) for x in tensors], axis)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:180 wrapper\n        return target(*args, **kwargs)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:1606 concat\n        return gen_array_ops.concat_v2(values=values, axis=axis, name=name)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py:1189 concat_v2\n        \"ConcatV2\", values=values, axis=axis, name=name)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:744 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py:595 _create_op_internal\n        compute_device)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:3327 _create_op_internal\n        op_def=op_def)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1817 __init__\n        control_input_ops, op_def)\n    /home/dishank/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1657 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimension 1 in both shapes must be equal, but are 7 and 30. Shapes are [?,7] and [?,30]. for '{{node model_4/concat_layer/concat}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](model_4/lstm_8/StatefulPartitionedCall:1, model_4/additive_attention_12/MatMul, model_4/concat_layer/concat/axis)' with input shapes: [?,7,100], [?,30,100], [] and with computed input tensors: input[2] = <2>.\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([text_train,sum_train[:,:-1]],\n",
    "                  sum_train.reshape(sum_train.shape[0],sum_train.shape[1], 1)[:,1:] ,\n",
    "                  epochs=10,callbacks=[es],batch_size=128,\n",
    "                  validation_data=([text_value,sum_value[:,:-1]], \n",
    "                sum_value.reshape(sum_value.shape[0],sum_value.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEw MDoal 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqSummarizer(object):\n",
    "\n",
    "    model_name = 'seq2seq'\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.num_input_tokens = config['num_input_tokens']\n",
    "        self.max_input_seq_length = config['max_input_seq_length']\n",
    "        self.num_target_tokens = config['num_target_tokens']\n",
    "        self.max_target_seq_length = config['max_target_seq_length']\n",
    "        self.input_word2idx = config['input_word2idx']\n",
    "        self.input_idx2word = config['input_idx2word']\n",
    "        self.target_word2idx = config['target_word2idx']\n",
    "        self.target_idx2word = config['target_idx2word']\n",
    "        self.config = config\n",
    "\n",
    "        self.version = 0\n",
    "        if 'version' in config:\n",
    "            self.version = config['version']\n",
    "\n",
    "        encoder_inputs = Input(shape=(None,), name='encoder_inputs')\n",
    "        encoder_embedding = Embedding(input_dim=self.num_input_tokens, output_dim=HIDDEN_UNITS,\n",
    "                                      input_length=self.max_input_seq_length, name='encoder_embedding')\n",
    "        encoder_lstm = LSTM(units=HIDDEN_UNITS, return_state=True, name='encoder_lstm')\n",
    "        encoder_outputs, encoder_state_h, encoder_state_c = encoder_lstm(encoder_embedding(encoder_inputs))\n",
    "        encoder_states = [encoder_state_h, encoder_state_c]\n",
    "\n",
    "        decoder_inputs = Input(shape=(None, self.num_target_tokens), name='decoder_inputs')\n",
    "        decoder_lstm = LSTM(units=HIDDEN_UNITS, return_state=True, return_sequences=True, name='decoder_lstm')\n",
    "        decoder_outputs, decoder_state_h, decoder_state_c = decoder_lstm(decoder_inputs,\n",
    "                                                                         initial_state=encoder_states)\n",
    "        decoder_dense = Dense(units=self.num_target_tokens, activation='softmax', name='decoder_dense')\n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "        model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "        self.encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "        decoder_state_inputs = [Input(shape=(HIDDEN_UNITS,)), Input(shape=(HIDDEN_UNITS,))]\n",
    "        decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_state_inputs)\n",
    "        decoder_states = [state_h, state_c]\n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "        self.decoder_model = Model([decoder_inputs] + decoder_state_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
